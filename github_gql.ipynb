{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from py_github.py_github import PyGithub\n",
    "import sqlite3\n",
    "import requests\n",
    "\n",
    "\n",
    "# load .env file\n",
    "load_dotenv()\n",
    "pygh_username = os.getenv(\"PYGH_USER\")\n",
    "pygh_token = os.getenv(\"PYGH_TOKEN\")\n",
    "pygh = PyGithub(pygh_username, pygh_token)\n",
    "\n",
    "sql_conn = sqlite3.connect(\"./data/github_gql.db\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def build_query(cursor = None):\n",
    "\n",
    "    cursor_string = f', after: \"{cursor}\"' if cursor else ''\n",
    "    base_query =f\"\"\"query {{\n",
    "      organization(login:\"torqata\") {{\n",
    "            repositories(first:1{cursor_string}) {{\n",
    "              pageInfo {{ endCursor }}\n",
    "              edges {{\n",
    "                node {{\n",
    "                  id\n",
    "              name\n",
    "              pullRequests(first:100, states:[MERGED] orderBy:{{field: CREATED_AT, direction:DESC}}){{\n",
    "                edges{{\n",
    "                  node{{\n",
    "                    id\n",
    "                    number\n",
    "                    title\n",
    "                    changedFiles\n",
    "                    createdAt\n",
    "                    closedAt\n",
    "                    merged\n",
    "                    mergedAt\n",
    "                    author {{\n",
    "                    login\n",
    "                    }}\n",
    "                    timelineItems(last: 1, itemTypes: [PULL_REQUEST_REVIEW]) {{\n",
    "                        nodes {{\n",
    "                        ... on PullRequestReview {{\n",
    "                            __typename\n",
    "                            author {{\n",
    "                              login\n",
    "                                }}\n",
    "                        createdAt\n",
    "                        state\n",
    "                            }}\n",
    "                        }}\n",
    "                      }}\n",
    "                    comments(first:1) {{\n",
    "                      totalCount\n",
    "                      edges {{\n",
    "                        node {{\n",
    "                          createdAt\n",
    "                        }}\n",
    "                      }}\n",
    "                    }}\n",
    "                  }}\n",
    "                }}\n",
    "              }}\n",
    "                }}\n",
    "              }}\n",
    "            }}\n",
    "      }}\n",
    "    }}\"\"\"\n",
    "\n",
    "    return base_query\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "def get_all_repos(cursor=None, repos=[]):\n",
    "    github_graphql = \"https://api.github.com/graphql\"\n",
    "    base_query = build_query(cursor)\n",
    "    response = requests.post(github_graphql, json={'query': base_query}, auth=(pygh_username, pygh_token))\n",
    "    resp_dict = response.json()\n",
    "    cursor = resp_dict['data']['organization']['repositories']['pageInfo']['endCursor']\n",
    "    if len(resp_dict['data']['organization']['repositories']['edges']) > 0:\n",
    "        repos.append(resp_dict['data']['organization']['repositories']['edges'][0])\n",
    "    if cursor:\n",
    "        repos = get_all_repos(cursor, repos)\n",
    "    return repos\n",
    "\n",
    "all_repos = get_all_repos()\n",
    "\n",
    "# all_repos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "145"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_repos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "2710"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytz\n",
    "\n",
    "prs = []\n",
    "for repo in all_repos:\n",
    "    repo = repo['node']\n",
    "\n",
    "    for pr in repo['pullRequests']['edges']:\n",
    "\n",
    "        pr_dict = {'repo_name': repo['name']}\n",
    "        pr = pr['node']\n",
    "        if not pr['closedAt']:\n",
    "            continue\n",
    "        created_date = datetime.strptime(pr['createdAt'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "        created_day_of_week = created_date.isoweekday()\n",
    "\n",
    "        pr_dict['number'] = pr['number']\n",
    "        pr_dict['number_of_files_changes'] = pr['changedFiles']\n",
    "        pr_dict['created_at'] = pr['createdAt']\n",
    "        pr_dict['created_at_eastern'] = created_date.astimezone(pytz.timezone('US/Eastern'))\n",
    "        pr_dict['created_day_week'] = created_day_of_week\n",
    "        pr_dict['closed_at'] = pr['closedAt']\n",
    "        pr_dict['comment_count'] = pr['comments']['totalCount']\n",
    "        pr_dict['merged'] = pr['merged']\n",
    "        pr_dict['merged_at'] = pr['mergedAt']\n",
    "\n",
    "        if pr.get('author'):\n",
    "            if pr['author']['login'] == 'dependabot':\n",
    "                continue\n",
    "            pr_dict['author'] = pr['author']['login']\n",
    "\n",
    "        closed_time = None\n",
    "\n",
    "        # get time to first approval on the pr. timeline items come back in asc date so we just need the first approved state\n",
    "        pr_dict['first_approval_time'] = None\n",
    "        pr_dict['first_approval_time_eastern'] = None\n",
    "        pr_dict['seconds_to_first_approval'] = None\n",
    "\n",
    "        if len(pr['timelineItems']['nodes']) > 0:\n",
    "            timeline_items = pr['timelineItems']['nodes']\n",
    "            for item in timeline_items:\n",
    "                if item['state'] == 'APPROVED':\n",
    "                    first_approval_time = datetime.strptime(item['createdAt'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                    first_approval_time_eastern = first_approval_time.astimezone(pytz.timezone('US/Eastern'))\n",
    "                    pr_dict['first_approval_time'] = first_approval_time\n",
    "                    pr_dict['first_approval_time_eastern'] = first_approval_time_eastern\n",
    "                    seconds_to_first_approval = first_approval_time - created_date\n",
    "                    pr_dict['seconds_to_first_approval'] = seconds_to_first_approval.seconds\n",
    "\n",
    "\n",
    "        # get the time till pr was merged\n",
    "        pr_dict['seconds_to_merge'] = None\n",
    "        if pr['mergedAt']:\n",
    "            merged_date = datetime.strptime(pr['mergedAt'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "            time_to_merge = merged_date - created_date\n",
    "            merged_time = time_to_merge.seconds\n",
    "            pr_dict['seconds_to_merge'] = merged_time\n",
    "\n",
    "        # time to first comment\n",
    "        pr_dict['first_comment_time'] = None\n",
    "        pr_dict['seconds_to_first_comment'] = None\n",
    "        if pr['comments']['totalCount'] > 0:\n",
    "            pr_dict['first_comment_time'] = pr['comments']['edges'][0]['node']['createdAt']\n",
    "            first_comment_date = datetime.strptime(pr_dict['first_comment_time'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "            time_to_first_comment = first_comment_date - created_date\n",
    "            pr_dict['seconds_to_first_comment'] = time_to_first_comment.seconds\n",
    "\n",
    "        prs.append(pr_dict)\n",
    "\n",
    "df = pd.DataFrame(prs)\n",
    "df.to_sql(\"repo_prs\", sql_conn, if_exists=\"replace\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}